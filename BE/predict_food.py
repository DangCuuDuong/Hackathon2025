import cv2
import numpy as np
import joblib
from collections import Counter
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import img_to_array

# === C·∫§U H√åNH ===
IMG_SIZE = (244, 244)
MODEL_PATH = 'BE/PKL/logistic_regression.pkl'
ENCODER_PATH = 'BE/PKL/label_encoder.pkl'

# === Load m√¥ h√¨nh ML + LabelEncoder ===
model = joblib.load(MODEL_PATH)
encoder = joblib.load(ENCODER_PATH)

# === Load m√¥ h√¨nh VGG16 tr√≠ch ƒë·∫∑c tr∆∞ng ===
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(244, 244, 3))
x = GlobalAveragePooling2D()(base_model.output)
vgg_model = Model(inputs=base_model.input, outputs=x)

# === H√†m x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o v√† tr√≠ch ƒë·∫∑c tr∆∞ng cho 1 v·∫≠t th·ªÉ ===
def extract_features_from_roi(roi):
    roi = cv2.resize(roi, IMG_SIZE)
    roi = img_to_array(roi)
    roi = preprocess_input(roi)
    roi = np.expand_dims(roi, axis=0)
    features = vgg_model.predict(roi)
    return features.flatten().reshape(1, -1)

# === H√†m nh·∫≠n di·ªán v√† ƒë·∫øm v·∫≠t th·ªÉ trong ·∫£nh ===
def predict_multiple_objects(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError("‚ùå ·∫¢nh kh√¥ng h·ª£p l·ªá!")

    orig_img = img.copy()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # L√†m gi√£n ƒë·ªÉ t√°ch v·∫≠t th·ªÉ
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    binary = cv2.dilate(binary, kernel, iterations=2)

    # S·ª≠ d·ª•ng connected components ƒë·ªÉ t√°ch t·ª´ng v·∫≠t th·ªÉ
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)

    results = []
    for i in range(1, num_labels):  # B·ªè nh√£n n·ªÅn
        x, y, w, h, area = stats[i]
        if area < 300:  # B·ªè nhi·ªÖu
            continue

        roi = orig_img[y:y+h, x:x+w]
        roi_resized = cv2.resize(roi, IMG_SIZE)
        roi_array = img_to_array(roi_resized)
        roi_array = preprocess_input(roi_array)
        roi_array = np.expand_dims(roi_array, axis=0)

        feature = vgg_model.predict(roi_array).flatten().reshape(1, -1)
        pred = model.predict(feature)
        label = encoder.inverse_transform(pred)[0]
        results.append(label)

        # V·∫Ω bounding box v√† nh√£n
        cv2.rectangle(orig_img, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(orig_img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (36, 255, 12), 2)

    # L∆∞u ·∫£nh k·∫øt qu·∫£
    cv2.imwrite("output_detected.png", orig_img)

    from collections import Counter
    return Counter(results)


# === Test th·ª≠ ===
if __name__ == "__main__":
    image_path = 'image.png'  # ·∫£nh b·∫°n v·ª´a g·ª≠i
    counts = predict_multiple_objects(image_path)

    print("üìä K·∫øt qu·∫£ nh·∫≠n di·ªán v√† ƒë·∫øm v·∫≠t th·ªÉ:")
    for label, count in counts.items():
        print(f" - {label}: {count}")

    print("üì∑ ·∫¢nh ƒë√£ l∆∞u t·∫°i: output_detected.png (c√≥ v·∫Ω khung + nh√£n)")
